# 即刻 AI 产品助理冲刺计划（双重项目强度保留版）

## Summary
你保持“双项目高强度”是可行的，前提是把交付从“功能导向”改成“验证导向”。  
本版计划保留：
1. 主项目重：`播客 AI 高光助手`
2. 副项目重：`社区内容 AI 整理员`
3. 同时新增：`产品能力证据层`，解决你“非产品背景”短板

成功标准：
1. 两个项目都能演示完整闭环
2. 每个项目都有可量化验证结论
3. 面试时能讲清“为什么做、如何验证、怎么迭代”

---

## 阶段 1：岗位对齐与叙事重构（必须先完成）

### 目标
将你的身份从“前后端工程实习生”重构为“技术型 AI 产品助理候选人”。

### 产出
1. `定位陈述`（60秒版）
2. `简历重写稿`（AI 产品助理定向）
3. `能力映射表`（技术能力 -> JD能力）

### 能力映射（固定口径）
1. 需求拆解：把模糊需求拆成可验证任务
2. 技术打样：快速搭建文字/音视频 AI MVP
3. 实验评估：定义指标并做对照复盘
4. 协作推进：跨角色对齐节奏与风险

### Gate
- 你能在 60 秒内说清自己和岗位的匹配逻辑，不依赖“我技术不错”这类泛表达。

---

## 阶段 2：统一项目规范（双项目共用操作系统）

### 目标
先建立统一工程与验证框架，避免两个项目风格割裂、材料不可比。

### 统一目录规范（两个仓库一致）

1. `README.md`：问题、场景、方案、指标、结果、局限
2. `docs/prd-lite.md`：1页产品说明（目标用户、MVP、成功指标）
3. `docs/experiment-log.md`：实验记录
4. `docs/decision-log.md`：关键取舍与理由
5. `demo/`：2-3分钟演示素材
6. `evaluation/`：评估样本与评分规则

### 统一评估指标（两个项目同口径）
1. 质量：输出相关性、准确性、可用性
2. 速度：端到端耗时、响应稳定性
3. 成本：单次请求估算成本
4. 稳定性：失败率、重试成功率

### Gate
- 两个项目可用同一套指标横向比较，不再是“各讲各的”。

---

## 阶段 3：主项目重实施（播客 AI 高光助手）

### 项目定位
贴近小宇宙场景，解决“长音频信息密度高、分享门槛高”的问题。

### 核心功能（强度保留）
1. 音频转写与时间戳分段
2. 高光提取与理由解释
3. 分享卡片与评论草稿生成
4. 结果可编辑与再次生成
5. 实验版本对比（不同策略/提示词）

### 接口契约（固定）
1. `POST /api/transcribe` -> `{transcript, segments, latencyMs, error?}`
2. `POST /api/highlights` -> `{highlights:[{start,end,quote,reason,score}], version}`
3. `POST /api/share-card` -> `{headline,summary,commentDrafts,tags}`
4. `POST /api/evaluate` -> `{scores:{quality,speed,cost,stability}, notes}`

### 必做验证场景
1. 短音频、长音频、噪声音频
2. 转写失败与超时回退
3. 高光提取偏移与冗余
4. 分享草稿安全性与语气控制

### Gate
- 完整闭环可演示，且有明确“有效策略/无效策略”结论。

---

## 阶段 4：副项目重实施（社区内容 AI 整理员）

### 项目定位
贴近即刻社区信息流场景，解决“讨论长、观点散、回复难”的问题。

### 核心功能（强度保留）
1. 长帖与评论流双层总结（速读版/深读版）
2. 观点聚类与分歧点提炼
3. 评论草稿多语气生成
4. 证据引用（每条观点关联原评论）
5. 敏感表达与偏见风险提示

### 接口契约（固定）
1. `POST /api/summarize-thread` -> `{summaryShort,summaryLong,keyPoints}`
2. `POST /api/cluster-opinions` -> `{clusters,disagreements,evidenceMap}`
3. `POST /api/reply-draft` -> `{drafts:[{tone,text,riskHint}], constraintsApplied}`
4. `POST /api/evaluate` -> `{scores:{compression,faithfulness,safety,usability}, notes}`

### 必做验证场景
1. 高冲突讨论串
2. 低信息密度灌水串
3. 观点极化场景
4. 回复语气越界场景

### Gate
- 能证明“减少信息负担、提升互动效率”，不只是“能生成文本”。

---

## 阶段 5：产品能力证据层（你从技术转产品的关键）

### 目标
把“会做项目”升级为“会做产品验证”。

### 每个项目必须交付 3 份文档
1. `PRD-Lite`：问题定义、用户画像、MVP范围、成功指标
2. `Experiment Report`：实验设计、样本、结果、结论、下一步
3. `Decision Log`：至少 5 个关键取舍（含放弃方案）

### 强制取舍维度（面试高频）
1. 质量 vs 速度
2. 成本 vs 效果
3. 自动化程度 vs 可控性
4. 功能广度 vs 场景深度

### Gate
- 面试中每个取舍都能落到“真实实验记录”，而非抽象观点。

---

## 阶段 6：作品集封装（GitHub + 单页站）

### 目标
让面试官 3-5 分钟完成有效判断。

### 单页站结构（固定）
1. 你的定位与岗位匹配
2. 项目A卡片（问题、方案、指标、Demo、仓库）
3. 项目B卡片（问题、方案、指标、Demo、仓库）
4. 统一方法论（需求 -> 假设 -> 实验 -> 结论）
5. 联系与社交证明（即刻/小宇宙/GitHub）

### 呈现标准
1. 每项目 1 张架构图
2. 每项目 1 张指标变化图
3. 每项目 1 段失败复盘
4. 链接都可直接访问和复现

### Gate
- 不看代码也能看懂你的价值；看代码可验证你具备实现能力。

---

## 阶段 7：面试系统训练（JD 定向）

### 目标
让你在“无产品经理经历”前提下依旧有专业表达。

### 必备回答模块
1. 为什么从技术走向 AI 产品助理
2. 如何把业务问题拆成可验证实验
3. 如何定义打样成功
4. 如何处理模型不稳定/成本超预算
5. 如何与产品、设计、研发对齐节奏

### 证据化面试包
1. 两项目 3 分钟讲稿
2. 两项目 10 个追问点与标准答法
3. 3 个 STAR 案例（WebGIS、L4、AI项目）
4. 1 页“我学到的产品方法”总结

### Gate

- 任意追问都能回到“场景-数据-决策-结果”链路。

---

## 阶段 8：投递与反馈闭环

### 目标
基于真实反馈迭代，不盲目补功能。

### 机制
1. 每轮投递记录版本号（简历/作品集/项目）
2. 面试反馈归因到具体环节（叙事、项目、知识、表达）
3. 每轮仅改 1-2 个核心变量再投递

### Gate
- 材料质量随轮次收敛，面试表现可持续提升。

---

## 测试与验收（全局）

### 功能验收
1. 两项目均可端到端演示
2. 异常输入可处理
3. 结果可导出、可复现

### 质量验收
1. 每项目至少一组结构化实验记录
2. 每项目有明确失败案例与修正策略
3. 指标对比能支持“迭代有效”结论

### 面试验收
1. 60秒自我介绍可稳定输出
2. 3分钟项目讲解不跑题
3. 追问下能讲取舍与边界

---

## Assumptions & Defaults
1. 技术栈默认：`React + TypeScript + Node.js`
2. 优先级默认：`验证闭环 > 功能堆叠 > 页面精修`
3. 双项目强度保持不降，但通过统一框架降低管理成本
4. 目标默认：优先拿到面试，再迭代深度与精度
